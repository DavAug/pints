{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interfacing with Stan\n",
    "This notebook explains how it is possible to interface with [Stan](https://mc-stan.org/) to make use of their log-probability calculations, gradient calculation (via autodiff) and their large library of probability distributions.\n",
    "\n",
    "One thing to be mindful of is that the interface below only allows the log probability to be accessed from Stan objects up to an additive constant.\n",
    "\n",
    "In this notebook, we use the [Eight Schools example](http://pints.readthedocs.io/en/latest/toy/eight_schools.html) and show how the model can be defined in Stan but called from in Pints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pystan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Stan model using their syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code=\"\"\"\n",
    "data {\n",
    "  int<lower=0> J;\n",
    "  real y[J];\n",
    "  real<lower=0> sigma[J];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real mu;\n",
    "  real<lower=0> tau;\n",
    "  real theta[J];\n",
    "}\n",
    "\n",
    "model {\n",
    "  mu ~ normal(0, 5);\n",
    "  tau ~ cauchy(0, 5);\n",
    "  theta ~ normal(mu, tau);\n",
    "  y ~ normal(theta, sigma);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compile Stan model (we also show code below to save the compiled model to avoid having to redo compilation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# sm = pystan.StanModel(model_code=code)\n",
    "\n",
    "# to pickle compiled model\n",
    "# with open('model.pkl', 'wb') as f:\n",
    "#     pickle.dump(sm, f)\n",
    "\n",
    "# to load pickled compiled model\n",
    "sm = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Eight Schools (\"centered\" parameterisation) model from Pints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "import pints\n",
    "import pints.toy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.stats\n",
    "\n",
    "model = pints.toy.EightSchoolsCenteredLogPDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the data provided with Pints' toy model to run Stan's NUTS for a few iterations (only needed so that we can access the functions bound to a stanfit object, so ignore warnings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:1 of 5 iterations ended with a divergence (20 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    }
   ],
   "source": [
    "fit = sm.sampling(data=model.data(), iter=10, chains=1, verbose=True, refresh=10)\n",
    "names = fit.unconstrained_param_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `pints.LogPDF` that wraps stanfit object. In doing this, it is important to note that we will be using the `log_prob` and `grad_log_prob` functions bound to the stanfit object to calculate the log probability and gradient (both of which remove any constants from the log probability). These functions operate in an unconstrained space, so we also need to use the `unconstrain_pars` argument to convert constrained parameters to be unconstrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EightSchoolsStanLogPDF(pints.LogPDF):\n",
    "    def __init__(self, stanfit):\n",
    "        self._fit = stanfit\n",
    "        self._log_prob = stanfit.log_prob\n",
    "        self._grad_log_prob = stanfit.grad_log_prob\n",
    "        # Stan takes dictionary of parameter values\n",
    "        self._dict_dynamic = {'mu':1, 'tau':1, 'theta': [2] * 8}\n",
    "        # convert variables from unconstrained to constrained space\n",
    "        self._u_to_c = stanfit.unconstrain_pars\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # handle case when tau < 0 is proposed (otherwise Stan throws error)\n",
    "        if x[1] < 0:\n",
    "            print(\"hello\")\n",
    "            return -np.inf\n",
    "        self._dict_update(x)\n",
    "        return self._log_prob(self._u_to_c(self._dict_dynamic), adjust_transform=True)\n",
    "    \n",
    "    def _dict_update(self, x):\n",
    "        self._dict_dynamic[\"mu\"] = x[0]\n",
    "        self._dict_dynamic[\"tau\"] = x[1]\n",
    "        self._dict_dynamic[\"theta\"] = x[2:]\n",
    "    \n",
    "    def evaluateS1(self, x):\n",
    "        # handle case when tau < 0 is proposed (otherwise Stan throws error)\n",
    "        if x[1] < 0:\n",
    "            return -np.inf, np.repeat(1e6,10)\n",
    "        self._dict_update(x)\n",
    "        uncons = self._u_to_c(self._dict_dynamic)\n",
    "        return self._log_prob(uncons, adjust_transform=True), self._grad_log_prob(uncons, adjust_transform=True)\n",
    "\n",
    "    def n_parameters(self):\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run [relativistic HMC](../sampling/relativistic-mcmc.ipynb) sampler using this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Using Relativistic MCMC\n",
      "Generating 4 chains.\n",
      "Running in sequential mode.\n",
      "Iter. Eval. Accept.   Accept.   Accept.   Accept.   Time m:s\n",
      "0     4      0         0         0         0          0:00.0\n",
      "1     84     0.333     0.333     0.333     0.333      0:00.0\n",
      "2     164    0.5       0.25      0.5       0.5        0:00.0\n",
      "3     244    0.6       0.4       0.6       0.4        0:00.0\n",
      "400   32004  0.627     0.657     0.888     0.821      0:05.8\n"
     ]
    }
   ],
   "source": [
    "# instantiate Pints version of Stan model\n",
    "stanmodel = EightSchoolsStanLogPDF(fit)\n",
    "\n",
    "# initialise\n",
    "xs = [np.random.normal(size=10) for chain in range(4)]\n",
    "# set 1st element of each list to positive number since corresponds to a scale parameter\n",
    "for x in xs:\n",
    "    x[1] = np.random.uniform()\n",
    "\n",
    "mcmc = pints.MCMCController(stanmodel, len(xs), xs, method=pints.RelativisticMCMC)\n",
    "\n",
    "# Add stopping criterion\n",
    "mcmc.set_max_iterations(2000)\n",
    "\n",
    "# Set up modest logging\n",
    "mcmc.set_log_to_screen(True)\n",
    "mcmc.set_log_interval(400)\n",
    "\n",
    "# # Update step sizes used by individual samplers\n",
    "for sampler in mcmc.samplers():\n",
    "    sampler.set_leapfrog_step_size(0.2)\n",
    "\n",
    "start = time.time()\n",
    "# Run!\n",
    "print('Running...')\n",
    "full_chains = mcmc.run()\n",
    "print('Done!')\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pints.MCMCSummary(chains=full_chains, time=(end-start), parameter_names=fit.unconstrained_param_names())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wandering chains here illustrate how difficult inference is for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints.plot\n",
    "pints.plot.trace(full_chains)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to hammer home the differences between Stan's log probability and Pints': we can compare them for sets of parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.random.uniform(size=10)\n",
    "\n",
    "pintsmodel = pints.toy.EightSchoolsCenteredLogPDF()\n",
    "\n",
    "print(str(\"Stan log prob: \" + str(stanmodel(params))))\n",
    "print(str(\"Pints log prob: \" + str(pintsmodel(params))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for sensitivities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, dp1 = stanmodel.evaluateS1(params)\n",
    "p2, dp2 = pintsmodel.evaluateS1(params)\n",
    "\n",
    "print(str(\"Stan d log(prob)/dmu: \" + str(dp1[0])))\n",
    "print(str(\"Pints d log(prob)/dmu: \" + str(dp2[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-centered model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed things up, we can move to Stan's non-centered parameterisation. (Pints also has a version of this model: ) This model introduces auxillary variables $\\tilde{\\theta}_j$ which ensure the joint distribution: $p(\\mu,\\tau, \\boldsymbol{\\theta})$ remains the same, but is easier to sample from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code=\"\"\"\n",
    "data {\n",
    "  int<lower=0> J;\n",
    "  real y[J];\n",
    "  real<lower=0> sigma[J];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real mu;\n",
    "  real<lower=0> tau;\n",
    "  real theta_tilde[J];\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  real theta[J];\n",
    "  for (j in 1:J)\n",
    "    theta[j] = mu + tau * theta_tilde[j];\n",
    "}\n",
    "\n",
    "model {\n",
    "  mu ~ normal(0, 5);\n",
    "  tau ~ cauchy(0, 5);\n",
    "  theta_tilde ~ normal(0, 1);\n",
    "  y ~ normal(theta, sigma);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile Stan model and run it for a few iterations to get a stanfit object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "sm = pystan.StanModel(model_code=code)\n",
    "\n",
    "# to pickle compiled model\n",
    "with open('model_ncp.pkl', 'wb') as f:\n",
    "    pickle.dump(sm, f)\n",
    "\n",
    "# to load pickled compiled model\n",
    "sm = pickle.load(open('model_ncp.pkl', 'rb'))\n",
    "\n",
    "# Run Stan model for a few iterations\n",
    "fit = sm.sampling(data=model.data(), iter=10, chains=1, verbose=True, refresh=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the Stan model in Pints. Note that the parameter names have changed from 'theta' to 'theta.tilde'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EightSchoolsNonCenteredStanLogPDF(pints.LogPDF):\n",
    "    def __init__(self, stanfit):\n",
    "        self._fit = stanfit\n",
    "        self._log_prob = stanfit.log_prob\n",
    "        self._grad_log_prob = stanfit.grad_log_prob\n",
    "        # Stan takes dictionary of parameter values\n",
    "        self._dict_dynamic = {'mu':1, 'tau':1, 'theta_tilde': [2] * 8}\n",
    "        # convert variables from unconstrained to constrained space\n",
    "        self._u_to_c = stanfit.unconstrain_pars\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # handle case when tau < 0 is proposed (otherwise Stan throws error)\n",
    "        if x[1] < 0:\n",
    "            print(\"hello\")\n",
    "            return -np.inf\n",
    "        self._dict_update(x)\n",
    "        return self._log_prob(self._u_to_c(self._dict_dynamic), adjust_transform=True)\n",
    "    \n",
    "    def _dict_update(self, x):\n",
    "        self._dict_dynamic[\"mu\"] = x[0]\n",
    "        self._dict_dynamic[\"tau\"] = x[1]\n",
    "        self._dict_dynamic[\"theta_tilde\"] = x[2:]\n",
    "    \n",
    "    def evaluateS1(self, x):\n",
    "        # handle case when tau < 0 is proposed (otherwise Stan throws error)\n",
    "        if x[1] < 0:\n",
    "            return -np.inf, np.repeat(1e6,10)\n",
    "        self._dict_update(x)\n",
    "        uncons = self._u_to_c(self._dict_dynamic)\n",
    "        return self._log_prob(uncons, adjust_transform=True), self._grad_log_prob(uncons, adjust_transform=True)\n",
    "\n",
    "    def n_parameters(self):\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retry sampling, this time with the non-centered parameterisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Pints version of Stan model\n",
    "stanmodel = EightSchoolsNonCenteredStanLogPDF(fit)\n",
    "\n",
    "# initialise\n",
    "xs = [np.random.normal(size=10) for chain in range(4)]\n",
    "# set 1st element of each list to positive number since corresponds to a scale parameter\n",
    "for x in xs:\n",
    "    x[1] = 5+np.random.uniform()\n",
    "\n",
    "mcmc = pints.MCMCController(stanmodel, len(xs), xs, method=pints.HamiltonianMCMC)\n",
    "\n",
    "# Add stopping criterion\n",
    "mcmc.set_max_iterations(4000)\n",
    "\n",
    "# Set up modest logging\n",
    "mcmc.set_log_to_screen(True)\n",
    "mcmc.set_log_interval(200)\n",
    "\n",
    "# # Update step sizes used by individual samplers\n",
    "for sampler in mcmc.samplers():\n",
    "    sampler.set_leapfrog_step_size(0.2)\n",
    "\n",
    "start = time.time()\n",
    "# Run!\n",
    "print('Running...')\n",
    "full_chains = mcmc.run()\n",
    "print('Done!')\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain $\\theta_j = \\mu + \\tilde{\\theta}_j \\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chains_transformed = []\n",
    "for i in range(len(full_chains)):\n",
    "    mu = full_chains[i][:, 0]\n",
    "    tau = full_chains[i][:, 1]\n",
    "    theta_tilde_j = full_chains[i][:, 2:]\n",
    "    full_chains_transformed.append(\n",
    "        np.concatenate((np.transpose(np.vstack((mu, tau))),\n",
    "                        mu[:, np.newaxis] + (theta_tilde_j * tau[:, np.newaxis])),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaaahh, that's better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pints.MCMCSummary(chains=full_chains_transformed,\n",
    "                            time=(end-start), parameter_names=names)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...much more efficient sampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints.plot\n",
    "pints.plot.trace(full_chains_transformed)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
